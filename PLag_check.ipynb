{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOx4jiF-puiD",
        "outputId": "857eeef0-8961-46ec-86a3-ed8ea19fec32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity data:\n",
            " ('Arthur.txt', 'Ben.txt', 0.4595329317649594)\n",
            "Similarity data:\n",
            " ('Ben.txt', 'Clark.txt', 0.4089048844003469)\n",
            "Similarity data:\n",
            " ('Arthur.txt', 'Clark.txt', 0.5430431121089814)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Python Program to Check Plagiarism\n",
        "'''\n",
        "\n",
        "# Import necessary modules!\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "student_files = [doc for doc in os.listdir() if doc.endswith('.txt')] # Make a list for the given files\n",
        "student_notes = [open(_file, encoding='utf-8').read()\n",
        "                 for _file in student_files]                           # Read  the contents of each stu text file\n",
        "\n",
        "def vectorize(Text): return TfidfVectorizer().fit_transform(Text).toarray()\n",
        "def similarity(doc1, doc2): return cosine_similarity([doc1, doc2])     #Assign similarity between two files\n",
        "# ML models only take i/p of numeric data\n",
        "# convert them from text into numeric we use TD-IDF\n",
        "\n",
        "vectors = vectorize(student_notes)\n",
        "s_vectors = list(zip(student_files, vectors))          # collection of all the 3 files uploaded in form od=f a list\n",
        "plagiarism_results = set()\n",
        "\n",
        "\n",
        "def check_plagiarism():\n",
        "    global s_vectors\n",
        "    for student_a, text_vector_a in s_vectors:\n",
        "        new_vectors = s_vectors.copy()                # copies file\n",
        "        current_index = new_vectors.index((student_a, text_vector_a)) #using indexes to extract file\n",
        "        del new_vectors[current_index]\n",
        "        for student_b, text_vector_b in new_vectors:  #declare in new vector\n",
        "            sim_score = similarity(text_vector_a, text_vector_b)[0][1]  # comp using similarity function creation\n",
        "            student_pair = sorted((student_a, student_b))   # to remove/prevent duplication in  the two texts\n",
        "            score = (student_pair[0], student_pair[1], sim_score)\n",
        "            plagiarism_results.add(score) # adds the value int he empty set plagiarism_results and by for stores allt he data in it\n",
        "    return plagiarism_results\n",
        "\n",
        "\n",
        "for data in check_plagiarism():\n",
        "    print(\"Similarity data:\\n\", data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0VWTXKJuP6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}